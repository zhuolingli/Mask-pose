# Copyright (c) OpenMMLab. All rights reserved.
import json
import os
import re
import time
import warnings
import torch
import cv2
import numpy as np
# import xmltodict
# from xtcocotools.coco import COCO
import json
from xtcocotools.coco import COCO
np.random.seed(0)


def list_all_files(root_dir, ext='.json'):
    """List all files in the root directory and all its sub directories.

    :param root_dir: root directory
    :param ext: filename extension
    :return: list of files
    """
    files = []
    file_list = os.listdir(root_dir)
    for i in range(0, len(file_list)):
        path = os.path.join(root_dir, file_list[i])
        if os.path.isdir(path):
            files.extend(list_all_files(path, ext))
        if os.path.isfile(path):
            if path.lower().endswith(ext):
                files.append(path)
    return files

def get_anno_info():
    keypoints_info = [
        'head',
        'back',
        'tail',
    ]
    skeleton_info = [[0,1],
                     [1,2]]

    category_info = [{
        'supercategory': 'rat',
        'id': 1,
        'name': 'rat',
        'keypoints': keypoints_info,
    }]

    return keypoints_info, skeleton_info, category_info

def json2coco_trainval(file_list, save_path, start_ann_id=0):
    """Save annotations in coco-format.

    :param file_list: list of data annotation files.
    :param save_path: the path to save transformed annotation file.
    :param start_ann_id: the starting point to count the annotation id.
    """
    images = []
    annotations = []
    img_ids = []
    ann_ids = []

    ann_id = start_ann_id

    name2id = {
        'head': 0,
        'back': 1,
        'tail': 2,
    }

    for idx, file in enumerate(file_list):
        with open(file, 'rb') as f:
            content = json.load(f)
        # dict_keys(['version', 'flags', 'shapes', 'imagePath', 'imageData', 'imageHeight', 'imageWidth'])
        data_anno = content['shapes']

        img_id = idx

        if img_id not in img_ids:
            image_name = content['imagePath'] # 路径作为图片名
            
            # 图片名也是加载图片的路径，需要矫正
            pre = os.path.join(*file.split(file.split('/')[-2])[0].split('/')[2:4])
            
            _, pre2, post = image_name.split('..')[-1].split('\\')
            image_name = os.path.join(pre2, post)
            image_name = os.path.join(pre, image_name)
            image = {}
            image['id'] = img_id
            image['file_name'] = image_name
            image['height'] = content['imageHeight']
            image['width'] = content['imageWidth']

            images.append(image)
            img_ids.append(img_id)
        else:
            pass

        # sparse annotations in one img
        bboxes = []
        for anno in data_anno:
            if anno['shape_type'] == 'rectangle':
                bboxes.append(anno['points']) # [[w1, h1],[w2,h2]]

        split_points = [{'bbox': bbox} for bbox in bboxes]

        for idx, bbox in enumerate(bboxes):
            for anno in data_anno:
                if anno['shape_type'] == 'point':
                    w, h = anno['points'][0] # [w, h]
                    if bbox[0][0]<w<bbox[1][0] and bbox[0][1]<h<bbox[1][1]:
                        split_points[idx].update({anno['label']: [w, h]})
        keypoint_num = 3

        for points in split_points:
            keypoints = np.zeros([keypoint_num, 3], dtype=np.float32)
            for kpt_name, point in points.items():
                if kpt_name != 'bbox':
                    kpt_id = name2id[kpt_name]
                    keypoints[kpt_id, 0] = float(point[0])
                    keypoints[kpt_id, 1] = float(point[1])
                    keypoints[kpt_id, 2] = 2

            anno = {}
            anno['keypoints'] = keypoints.reshape(-1).tolist()
            anno['image_id'] = img_id
            anno['id'] = ann_id
            anno['num_keypoints'] = int(sum(keypoints[:, 2] > 0))

            # 给定 bbox
            visible_bounds = points['bbox']
            anno['bbox'] = [
                float(visible_bounds[0][0]),  #左上坐标，和bbox的宽高
                float(visible_bounds[0][1]),
                float(visible_bounds[1][0] - visible_bounds[0][0]),
                float(visible_bounds[1][1] - visible_bounds[0][1] )
            ]
            anno['iscrowd'] = 0
            anno['area'] = float(anno['bbox'][2] * anno['bbox'][3])
            anno['category_id'] = 1

            annotations.append(anno)
            ann_ids.append(ann_id)
            ann_id += 1

    cocotype = {}
    cocotype['info'] = {}
    cocotype['info'][
        'description'] = 'rat dataset Generated by meyself'
    cocotype['info']['version'] = '1.0'
    cocotype['info']['year'] = time.strftime('%Y', time.localtime())
    cocotype['info']['date_created'] = time.strftime('%Y/%m/%d',
                                                     time.localtime())
    cocotype['images'] = images
    cocotype['annotations'] = annotations
    keypoints_info, skeleton_info, category_info = get_anno_info()

    cocotype['categories'] = category_info

    os.makedirs(os.path.dirname(save_path), exist_ok=True)
    json.dump(cocotype, open(save_path, 'w'), indent=4)
    print('number of images:', len(img_ids))
    print('number of annotations:', len(ann_ids))
    print(f'done {save_path}')

def split_train_val(work_dir, trainval_file, train_file, val_file,
                    val_ann_num):
    """Split train-val json file into training and validation files.

    :param work_dir: path to load train-val json file, and save split files.
    :param trainval_file: The input json file combining both train and val.
    :param trainval_file: The output json file for training.
    :param trainval_file: The output json file for validation.
    :param val_ann_num: the number of validation annotations.
    """

    coco = COCO(os.path.join(work_dir, trainval_file))

    img_list = list(coco.imgs.keys())
    np.random.shuffle(img_list)

    count = 0

    images_train = []
    images_val = []
    annotations_train = []
    annotations_val = []

    for img_id in img_list:
        ann_ids = coco.getAnnIds(img_id)

        if count + len(ann_ids) <= val_ann_num:
            # for validation
            count += len(ann_ids)
            images_val.append(coco.imgs[img_id])
            for ann_id in ann_ids:
                annotations_val.append(coco.anns[ann_id])

        else:
            images_train.append(coco.imgs[img_id])
            for ann_id in ann_ids:
                annotations_train.append(coco.anns[ann_id])

    if count == val_ann_num:
        print(f'We have found {count} annotations for validation.')
    else:
        warnings.warn(
            f'We only found {count} annotations, instead of {val_ann_num}.')

    cocotype_train = {}
    cocotype_val = {}

    keypoints_info, skeleton_info, category_info = get_anno_info()

    cocotype_train['info'] = {}
    cocotype_train['info'][
        'description'] = 'AnimalPose dataset Generated by MMPose Team'
    cocotype_train['info']['version'] = '1.0'
    cocotype_train['info']['year'] = time.strftime('%Y', time.localtime())
    cocotype_train['info']['date_created'] = time.strftime(
        '%Y/%m/%d', time.localtime())
    cocotype_train['images'] = images_train
    cocotype_train['annotations'] = annotations_train
    cocotype_train['categories'] = category_info

    json.dump(
        cocotype_train,
        open(os.path.join(work_dir, train_file), 'w'),
        indent=4)
    print('=========================================================')
    print('number of images:', len(images_train))
    print('number of annotations:', len(annotations_train))
    print(f'done {train_file}')

    cocotype_val['info'] = {}
    cocotype_val['info'][
        'description'] = 'AnimalPose dataset Generated by MMPose Team'
    cocotype_val['info']['version'] = '1.0'
    cocotype_val['info']['year'] = time.strftime('%Y', time.localtime())
    cocotype_val['info']['date_created'] = time.strftime(
        '%Y/%m/%d', time.localtime())
    cocotype_val['images'] = images_val
    cocotype_val['annotations'] = annotations_val
    cocotype_val['categories'] = category_info

    json.dump(
        cocotype_val, open(os.path.join(work_dir, val_file), 'w'), indent=4)
    print('=========================================================')
    print('number of images:', len(images_val))
    print('number of annotations:', len(annotations_val))
    print(f'done {val_file}')

def getStat(file_paths):
    '''
    Compute mean and variance for training data
    :param file_paths: img dirs
    :return: (mean, std)
    '''
    print('Compute mean and variance for training data.')
    print(f'find {len(file_paths)} imgs!')
    
    mean = torch.zeros(3)
    std = torch.zeros(3)
    for file_path in file_paths:
        img = cv2.imread(file_path)
        img = img.astype(np.float32) / 255
        for d in range(3):
            mean[d] += img[:, :, d].mean() # [B,c,h,w]
            std[d] += img[:, :, d].std()
    mean.div_(len(file_paths))
    std.div_(len(file_paths))
    return list(mean.numpy()), list(std.numpy())

dataset_dir = 'data/rat'

train_img_files = list_all_files(os.path.join(dataset_dir, 'train'), ext='.jpg')


mean, std = getStat(train_img_files)
print(f'mean:{mean} std:{std}')

# # # 78 images, 99 annotations

json2coco_trainval(list_all_files(os.path.join(dataset_dir, 'train')),
                os.path.join(dataset_dir, 'annotations', 'rat_trainval.json'))

# 不需要val 
split_train_val(
    os.path.join(dataset_dir, 'annotations'),
    'rat_trainval.json',
    'rat_train.json',
    'rat_val.json',
    val_ann_num=0)


json2coco_trainval(
    list_all_files(os.path.join(dataset_dir, 'test')),
    os.path.join(dataset_dir, 'annotations', 'rat_test.json'),
    start_ann_id=0)


# pass
